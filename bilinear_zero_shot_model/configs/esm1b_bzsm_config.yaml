phosphosite:
  dataset:
    train: ../Darkin_Dataset/datasets/random_seed_12345/ZSL/train_data_random_seed_12345.csv
    validation: ../Darkin_Dataset/datasets/random_seed_12345/ZSL/ZSL_validation_data_random_seed_12345.csv
    test: ../Darkin_Dataset/datasets/random_seed_12345/ZSL/ZSL_test_data_random_seed_12345.csv
    processor:
      processor_type: hf
      model_name: esm1b_t33_650M_UR50S
      read_embeddings: true
      phosphosite_embedding_path: /arf/scratch/esunar/DeepKinZero_2/extract_embeddings/merged_embeddings/ESM1B_Site_merged_embeddings.pt
      protvec_file_path: dataset/new_dataset/protvec_embeddings.txt
      split_multilabel_rows: false
  model:
    model_type: hf
    model_name: esm1b_t33_650M_UR50S
    embedding_mode: cls
    is_pretrained: true
    freeze: true
    unfrozen_layers: ''
    lora: false
    remove_layers: 0
    plot_residue_attentions: false
  
  sequence_model:
    model_type: bilstm
    hidden_size: 512
    use_sequence_model: false

kinase:
  dataset:
    train: ../Darkin_Dataset/data_files/kinase_properties.csv
    validation: ../Darkin_Dataset/data_files/kinase_properties.csv
    test: ../Darkin_Dataset/data_files/kinase_properties.csv
    train_val: ../Darkin_Dataset/data_files/kinase_properties.csv
    processor:
      processor_type: hf
      model_name: esm1b_t33_650M_UR50S
      read_embeddings: true
      kinase_embedding_path: /arf/scratch/esunar/DeepKinZero_2/extract_embeddings/merged_embeddings/ESM1BKinaseEmb_withattentionmask.pt
      protvec_file_path: 
      use_family: true
      use_group: true
      use_enzymes: true
      use_kin2vec: false
      use_pathway: false
      active_site:
        use_active_site: false
        from_context: false
        embedding_mode: cls
      use_domain: true
  model:
    model_type: hf
    model_name: esm1b_t33_650M_UR50S
    embedding_mode: cls
    is_pretrained: true
    freeze: true
    unfrozen_layers: ''
    lora: false

training:
  train_batch_size: 256
  test_batch_size: 256
  num_epochs: 100
  normalize_phosphosite_data: true
  normalize_kinase_data: false
  save_model: true
  set_seed: true
  precision: '32-true'
  loss_function: 'normalized_cross_entropy'

hyper_parameters:
  gamma : 0.9756514890680584
  learning_rate : 0.00259774443912184
  optimizer : 'SGD'
  scheduler_type : 'CosineAnnealingLR'
  weight_decay: 0.00011754554440719858
  temperature: 1.0
  focal_loss_gamma: 1.0
  use_weighted_loss: false
  loss_weight_type: 'pairwise_sim'
  use_soft_probs_ce: false

logging:
  wandb:
    use_wandb : false
    log_name : 'esm1b_w'
    project_name : 'transformer-training'
    entity_name : 'deepkinzero'
  local:
    run_test_suite: false
    use_config_filename: false
    save_predictions: false
    checkpoint_file_name: 'esm1b_w'
    saved_model_path: checkpoints/esm1b_models
    kinase_encoder_save_path : checkpoints/esm1b_models/ke_esm1b_w.pkl

lora_config:
  lora_rank: 8
  lora_alpha: 16
  lora_dropout: 0.05
  lora_query: true
  lora_key: true
  lora_value: true
  lora_output: true
  lora_intermediate: true